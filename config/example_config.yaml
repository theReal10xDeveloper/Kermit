llm:
  api_type: "openai"  # or azure / ollama / groq etc.
  base_url: "YOUR_BASE_URL"
  api_key: "YOUR_API_KEY"
  model: "gpt-4-turbo"  # or gpt-3.5-turbo
  proxy: "YOUR_PROXY"  # for LLM API requests
  timeout: 300 # Optional. If set to 0, default value is 300.


